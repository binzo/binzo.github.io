---
layout: post
title:  "Java并发"
date:   2019-01-15
categories: java
tags: [java, 并发]
published: true
---

本文总结java并发相关知识，记录并发编程中需要注意的问题，以及相关解决方法。

## 线程安全

在并发编程中线程安全是必须要保证的，无法保证线程安全，并发编程之后事都无从说起。在多线程环境中，不管采取什么调度方式，并且在调用代码中也不需要额外同步，这个类都能表现出正确的行为，那么就称这个类是线程安全的。而线程安全类中需要保证的就是状态（变量）的正确性，也就是说无状态对象一定是线程安全的。

为了保证线程安全，java提供了`synchronized`关键字、`volatile`关键字、Lock锁等机制。这些机制都是为了保证`原子性`和`可见性`。

`原子性`：即一个操作（有可能包含有多个子操作）要么全部执行（生效），要么全部都不执行（都不生效）。

例如常见的i++操作，如果在多线程中对同一个变量i执行i++操作，在执行100次后，其可能不是我们想要的100这个结果，其原因就是在a操作还没执行完，就已经有b操作对i进行了修改，但这次操作读取到的值还是b操作之前的值，从而导致a操作的加值不正确。为了避免在这一次操作中有其他操作可以修改状态，而导致的当前操作的不正确，所以我们必须保证当前操作不被其他因素影响。`synchronized`关键字和Lock都能保证原子性。

ps：即使操作中的各个子操作都是同步的，只要该操作不是原子的，依然会出现问题。如下例子：
``` java
//vector是java中线程安全集合，其中每个方法都是synchronized的，并发执行以下代码会出现多次添加a元素问题
if(!vector.contains(a))
    vector.add(a);
```

`可见性`

假设对变量a操作，一个线程执行a=3之后，另外一个线程读取a的值可能不是3。

会导致该问题的原因有很多，不只有以下因素：
- 编译器生成的指令顺序，可以与源代码中的顺序不同，此外编译器还会把变量保存在寄存器而不是内存中
- 处理器可以采用乱序或者并行等方式来执行指令
- 缓存可能会改变将写入变量提交到主内存的次序
- 保存在处理器本地缓存中的值，对其他处理器不可见

在单线程环境中这些策略不会影响程序运行结果，反而会加快运行速度；

java内存模型可以保证多线程操作可见性，JMM是通过各种操作来定义的，包括对变量的读写，监视器的加锁和释放操作，以及线程启动和合并操作。其中所有操作都满足Happen-before偏序关系。如果两个操作之间缺乏Happen-before关系，那么jvm可以对它们任意的重排序。
例如：
- 线程内执行的每个操作，都保证 happen-before 后面的操作，这就保证了基本的程序顺序规则，这是开发者在书写程序时的基本约定。
- 对于 volatile 变量，对它的写操作，保证 happen-before 在随后对该变量的读取操作。
- 对于一个锁的解锁操作，保证 happen-before 加锁操作。
- 对象构建完成，保证 happen-before 于 finalizer 的开始动作。
- 甚至是类似线程内部操作的完成，保证 happen-before 其他 Thread.join() 的线程等。

简单来说只要你符合happen-before规则（A happen-before B），那么执行操作B的线程就一定能看到操作A的结果（无论A和B是否在同一线程中执行）。
所以在上面`原子性`相关例子中其实也有可见性问题，假如i++操作能保证原子性，但由于i值结果可能对其他线程不可见，那么其他线程计算的结果就也可能出错，内置锁synchronized可以保证可见性。

ps：加锁机制即可以确保可见性又可以确保原子性，而volatile变量只能确保可见性。当且仅当满足以下**所有条件**时，才应该使用volatile变量：
- 对变量的写入操作不依赖变量当前值，或者你能保证只有单个线程更新变量的值
- 该变量不会与其他状态变量一起纳入不变性条件中
- 在防问该变量时不需要加锁

## 线程活跃性
为了保证线程安全，程序中会使用各种同步机制，就不可避免的会遇到一些活跃性问题。

### 死锁
死锁是最常见的活跃性问题，下面将总结一些常见类型死锁。

`锁顺序死锁`

A线程进入**lock1锁**请求**lock2锁**，B在A线程锁住**lock1锁**之后并且在A线程请求**lock2锁**之前进入**lock2锁**，然后请求**lock1锁**，这个时候A和B线程就会相互等待，从而死锁。

这种情况就是锁顺序死锁，简单来说就是每个线程对不同对象的加锁顺序不一致，如上面例子：A线程加锁顺序为**lock1**-->**lock2**,B线程加锁顺序为**lock2**-->**lock1**。

如果所有线程以固定的顺序来获取锁，那么在程序中就不会出现锁顺序死锁问题。

`资源死锁`：简单来说就是将等待的对象从锁变成了一些具体的资源；
- 如A线程持有D1数据库连接等待D2连接，B线程持有D2连接等待D1连接；
- 又如线程饥饿死锁：A任务（本身已在线程池中运行）提交B任务到线程池，并且等待B任务结果返回，如果线程池是单线程池，那么B任务将不能执行，也不能拿到结果，A任务将一直等待下去，线程池中其他任务也不能运行。

`避免死锁`
- 除了上面说的尽量保证嵌套锁加锁顺序一致，如果能避免使用嵌套锁的情况也能避免死锁。
- 还有一种支持定时的锁可以帮助我们从死锁中恢复，即显式使用Lock类中的tryLock功能，该方法带有超时机制，当等待超时时会返回一个失败信息（该方法只有在能同时获取到两个锁时才有效，如果在嵌套的方法调用中请求多个锁，那么即使你知道已经持有了外层锁，由于拿不到外层锁而无法释放它）。
- 另外通过线程转储信息也可以帮助我们分析死锁，在Linux系统上可以向jvm进程发送SIGQUIT信号（kill -3），就可以在输出的信息中看到进程中各线程的堆栈信息。

### 饥饿
当线程由于无法访问它所需要的资源而不能继续执行时，就发生了“饥饿”。引发饥饿最常见资源就是cpu时钟周期。如果在java应用程序中对线程的优先级使用不当，或者在持有锁时执行一些无法结束的结构（例如无限循环，或者无限等待某个资源），那么也可能导致饥饿，因为其他需要这个锁的线程将无法得到它。

要避免使用线程优先级，因为这会增加平台依赖性，并可能导致活跃性问题。在大多数并发应用程序中，都可以使用默认的线程优先级。

### 活锁

活锁通常发生在处理事务消息的程序中：如果不能成功的处理某个消息，那么消息处理机制将回滚整个事务，并将它重新放到队列开头。如果这个消息总是处理失败，那么该消息将一直回滚，虽然处理消息的线程并没有阻塞，但也无法执行下去。

另一种情况是当多个协作线程都因同时使用某一资源，而选择同时避让，而后又同时使用其他资源，而又同时避让，这样反复避让，又相互无法执行，也就发生了活锁。这种情况可以通过在重试机制中引入随机性来避免，例如选择重试的时间是随机的而不是每个都是固定的时间。

### 丢失信号

```java
synchronized(lock) {
    if (condition) {
        lock.wait();
    }
    // 执行其他操作
}
```
例如在上面这个例子中，在调用wait之后，当程序被唤醒时（各种原因会被唤醒），此时condition可能依然是true，而此时程序却会执行wait之后的操作，与预期不符。为了避免此问题需要将if修改成while，每当线程从wait中唤醒时，都必须再次测试条件是否正常。

## 性能

对于服务端和移动端应用来说，对于性能的考虑侧重点是不同的，对于服务器程序来说，由于计算资源是可以增加的，则可能更关注可伸缩性、吞吐量和生产量；而对于移动端来说，由于计算资源有限，而且有强交互性，所以对于延迟和响应速度更加关注，所以在优化时更在意提高单线程性能。本节将重点介绍可伸缩性相关优化。

`可伸缩性`：当增加计算资源时（例如cpu、内存、存储容量或者I/O带宽），程序的吞吐量或者处理能力能相应的增加。

考虑可伸缩性的目的其实就是为了能尽可能的利用计算资源，比如使cpu尽可能的保持忙碌状态，但是要在尽可能的保证cpu忙碌时都是在执行一些有用的工作。所以为了能充分使用计算资源，我们在设计程序时会将其分成各种不同的业务层，从而能达到分摊计算资源的目的；然而这些任务之间都是有联系的，必然存在一些任务需要等待其他任务完成，也就是说必然包含一些串行任务和一些并行任务。Amdahl定律可以告诉我们：在增加计算资源的情况下，程序理论上能够实现的最高加速比，这个值取决于程序中并行与串行任务的比重，串行任务越少加速比就越高。

`线程开销`

- `上下文切换`：当cpu将正在运行的线程调度出来，从而使其他线程能够使用cpu时，这将导致一次上下文切换，这个过程需要保存当前运行线程的执行上下文，并将新调度进来的线程上下文设置为当前上下文。当线程由于等待某个锁而被阻塞时，jvm就会将该线程挂起，并被允许交换出去，所以如果频繁的发生阻塞，就会增加cpu的调度开销，从而减少了正在执行任务的时间。
- `内存同步`：volatile、synchronized等同步机制会保证可见性，为了保证可见性，这些机制会增加内存总线上的通信量，而总线带宽是有限的，所以过多的内存同步会导致性能下降。

为了提高可伸缩性，我们就需要减少串行操作和上下文切换（内存同步的开销要小很多，只要没有达到总线的上线，其操作一般还是较快的），所以我们需要减少独占方式的资源锁的影响。
降低锁竞争程度：
- 减少锁的持有时间

缩小锁的范围，比如将开销较大的操作移出到锁外，但是这样可能会导致原子性问题，所以还是需要看具体需求，只能尽可能的减小范围。

- 降低锁的请求频率

如果整个程序的同步只有一个锁，那么请求频率是不是会很频繁？
减小锁的粒度：可以通过锁分解和锁分段等技术来实现。锁分解就是对不同的变量使用不同的锁来保护。锁分段技术的典型应用是ConcurrentHashMap（注意在java8不在使用该机制），在使用锁分段技术时我们应该尽量的将所有的状态都分段，例如map的size问题，如果只是分段了数据，那么每次求size都需要对所有段加锁，就有降低了性能，所以我们可以采取对每段进行size，然后相加的方式来计算size大小；使用了这种技术的数据结构必然会存在在遍历和获取size时可能不是最新的问题。

- 使用带有协调机制的独占锁或者放弃使用独占锁：例如ReadWriteLock读写锁，或者CAS机制

ReadWriteLock可以保证在有多个读数据时可以共享资源，而当有写数据时以独占的方式来获取锁，这个时候读也是不行；所以它可以提升在多读少写系统的可伸缩性。

CAS是一种非阻塞同步机制，例如AtomicIntger就使用该种机制来保证原子性，当多个线程尝试使用CAS同时更新一个变量时，只有其中一个线程能更新，其他线程都将失败，然后失败的线程并不会被挂起，而是被告知这次竞争中失败了，这个时候开发者可以自己决定要不要再次重试，所以使用CAS可以构建无阻塞算法。

CAS也并不是没有副作用，试想，其常用的失败重试机制，隐含着一个假设，即竞争情况是短暂的。大多数应用场景中，确实大部分重试只会发生一次就获得了成功，但是总是有意外情况，所以在有需要的时候，还是要考虑限制自旋的次数，以免过度消耗CPU。

另外一个就是著名的[ABA](https://en.wikipedia.org/wiki/ABA_problem)问题, CAS在更新时会比较前值，如果对方只是恰好相同，例如期间发生了 A -> B -> A 的更新，仅仅判断数值是 A，可能导致不合理的修改操作。针对这种情况，Java 提供了 AtomicStampedReference 工具类，通过为引用建立类似版本号（stamp）的方式，来保证 CAS 的正确性。

## 总结
本文从安全性、活跃性、性能三个方面总结了java并发相关问题，在个人看来安全性就是要保证程序是否能按照预期运行，而活跃性就是同步机制的使用错误，实际就是自己的考虑的不够完善，如果开发前能尽可能的列举可能出现的情况，也能帮助我们避免这些错误；而自从选择并发编程，基本就表示我们想提高性能，而性能的提升需要避免硬件和操作系统的额外开销，怎么能减少开销就怎么来，当然前提是你的功能正常。
